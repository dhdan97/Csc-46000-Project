{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exploratory_data_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xycf87AToKuT"
      },
      "source": [
        "<strong>Preliminary Analysis</strong> <br>\n",
        "\n",
        " Your preliminary analysis should include: <br>\n",
        "<ul>\n",
        "  <li><strong>Data Cleaning Code </strong> <br>\n",
        "        Code for cleaning and processing your data. Include a data dictionary for your transformed dataset. \n",
        "    <ul> \n",
        "      <li>\n",
        "      Data Dictionary:\n",
        "        <ul>\n",
        "            <li><strong>id</strong>: A unique identifier for each tweet</li>\n",
        "            <li><strong>text</strong>: the text of the tweet</li>\n",
        "            <li><strong>location</strong>: the location the tweet was sent</li>\n",
        "            <li><strong>keyword</strong>: a particular keyword from the tweet</li>\n",
        "            <li><strong>target</strong>: denotes whether a tweet is about a real disaster(1) or not(0)</li>\n",
        "        </ul>\n",
        "      </li> \n",
        "    </ul> \n",
        "  </li>\n",
        "  <li><strong>Exploratory Analysis </strong> <br>\n",
        "       Describe what work you have done so far and include the code. This may include descriptive statistics, graphs and charts, and preliminary models. \n",
        "    <ul> \n",
        "      <li>\n",
        "        For this preliminary analysis, we noticed that there were inconsistencies in the data columns so we adjusted them using the steps in the next bullet point.\n",
        "        <li>\n",
        "          The <strong>keyword</strong> column did not extract all the disaster keywords from the text. So we extracted the keyword column and text column and applied a function to extract the correct keywords by word tokenizing and extracting the words which intersect with the disaster word vector. \n",
        "        <li>\n",
        "          The same was done for the <strong>location</strong> column.\n",
        "        </li>\n",
        "        </li>\n",
        "      </li> \n",
        "    </ul> \n",
        "  </li>\n",
        "  <li><strong>Challenges </strong> <br>\n",
        "        Describe any challenges you've encountered so far. Let me know if there's anything you need help with! \n",
        "    <ul> \n",
        "      <li>\n",
        "        There were many challenges when attempting to correct the inconsistent data columns. \n",
        "      </li> \n",
        "      <li>\n",
        "          The <strong>keyword</strong> column wasn't as difficult but still came as a challenge as attempting the fillna using normal means wasnt working for us. But, we figured it out. \n",
        "      </li> \n",
        "      <li>\n",
        "        The <strong>location</strong> column was difficult. Hands down took the longest to implement and even now doesnt work correctly as there arent efficient and free NER libraries to extract 'GPE' from texts. We attempted using 3 different types, one of which included using <strong>spaCy</strong>, but that didnt work with Google Colab. The other two that we used were very time consuming to run. Took a whomping <strong>17~20 minutes</strong> when using on the train data set. \n",
        "      </li> \n",
        "    </ul> \n",
        "  </li>\n",
        "  <li><strong>Future Work </strong> <br>\n",
        "        Describe what work you are planning to complete for the final analysis.\n",
        "    <ul> \n",
        "      <li>Future work involves using our cleaned data and features as input for models suited for classification, like Naive Bayes and Logisitic Regression and training these models</li> \n",
        "      <li>Making predictions off our trained models and evaluating performance with accuracy scores and confusion matrices</li>\n",
        "      <li>Defining our grid of hyperparameter values and using GridSearchCV() to systematically find the best peforming model</li>\n",
        "      </ul> \n",
        "  </li>\n",
        "  <li><strong>Contributions </strong> <br>\n",
        "        Describe the contributions that each group member made. \n",
        "    <ul> \n",
        "      <li>\n",
        "      Daniel Hernandez\n",
        "      <ul> \n",
        "        <li>Found the data sets. \n",
        "        </li>\n",
        "        <li>Helped in brain storming. \n",
        "        </li> \n",
        "        <li>Created colab template\n",
        "        </li>\n",
        "        <li>Implemented visualizations\n",
        "        </li>\n",
        "        <li>Assisted in thinking of procedure to clean data columns.\n",
        "        </li>\n",
        "    </ul> \n",
        "      </li> \n",
        "      <li>\n",
        "      Justin Park\n",
        "      <ul> \n",
        "        <li>Helped in brain storming.\n",
        "        </li>\n",
        "        <li>Implemented functions to clean keyword and location columns.\n",
        "        </li> \n",
        "        <li>Implemented procedure to clean data columns.\n",
        "        </li>\n",
        "    </ul> \n",
        "      </li> \n",
        "    </ul> \n",
        "  </li>\n",
        "</ul>\n",
        " Your preliminary analysis does not have to be a formal writeup. You will submit your Github repository for your project.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZKbPLUj8A9Y"
      },
      "source": [
        "Notes for 11/17\n",
        "\n",
        "- How do we deal with empty values for Keyword and Location?\n",
        "- How would those columns be inputted into our model?\n",
        "- Are these columns worth adding to the model in the first place or should we omit them?\n",
        "- Should we normalize our tweets?\n",
        "- How should we tokenize our Tweets?\n",
        "<br>\n",
        "<br>\n",
        "<h2>Notes for 11/19 </h2>\n",
        "<strong>Data cleaning </strong>\n",
        "<ul>\n",
        "<li>clean location feature, there is dirty data such as dates, symbols, and numeric values. </li>\n",
        "<li>fill in NA values with numpy's NaN for machine learning. </li>\n",
        "<li>set up word vector for emergencies.</li>\n",
        "<li>use word vector to fill in NA values in the keyword section from text. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4GayAGKxjXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba51a89-36bf-4ea5-c6c5-5619b723a949"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from nltk import Tree\n",
        "import spacy\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')\n",
        "!pip install locationtagger\n",
        "import locationtagger\n",
        "import re\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: locationtagger in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.7/dist-packages (from locationtagger) (20.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from locationtagger) (3.2.5)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.7/dist-packages (from locationtagger) (0.2.8)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from locationtagger) (2.2.4)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (3.13)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (0.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (4.6.3)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (0.0.4)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (2.23.0)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (6.0.8)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (2.8.2)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (1.1.0)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (7.1.2)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->locationtagger) (3.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k->locationtagger) (1.15.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser>=5.2.1->newspaper3k->locationtagger) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->locationtagger) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->locationtagger) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->locationtagger) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->locationtagger) (2.10)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->locationtagger) (3.4.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->locationtagger) (1.5.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (4.62.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->locationtagger) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->locationtagger) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->locationtagger) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->locationtagger) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMyIcht8uyHC",
        "outputId": "2ad44fac-16b7-462e-c251-8cd878d97359"
      },
      "source": [
        "import nltk\n",
        "# essential entity models downloads\n",
        "nltk.downloader.download('maxent_ne_chunker')\n",
        "nltk.downloader.download('words')\n",
        "nltk.downloader.download('treebank')\n",
        "nltk.downloader.download('maxent_treebank_pos_tagger')\n",
        "nltk.downloader.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr1r6ZsaJbbw",
        "outputId": "2883c444-12b1-4b1a-aa72-c77168bef967"
      },
      "source": [
        "!pip install git+git://github.com/jmbielec/geograpy3.git \n",
        "!pip install git+https://github.com/jmbielec/geograpy3.git \n",
        "import geograpy3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/jmbielec/geograpy3.git\n",
            "  Cloning git://github.com/jmbielec/geograpy3.git to /tmp/pip-req-build-9s22t7im\n",
            "  Running command git clone -q git://github.com/jmbielec/geograpy3.git /tmp/pip-req-build-9s22t7im\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (3.2.5)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (0.8.9)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (20.7.3)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (0.2.8)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (0.3)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (4.2.6)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (3.13)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (4.6.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (6.0.8)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (0.35.1)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (0.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k->geograpy3==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser>=5.2.1->newspaper3k->geograpy3==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==1.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==1.0.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->geograpy3==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->geograpy3==1.0.0) (3.4.0)\n",
            "Collecting git+https://github.com/jmbielec/geograpy3.git\n",
            "  Cloning https://github.com/jmbielec/geograpy3.git to /tmp/pip-req-build-e2d9uig8\n",
            "  Running command git clone -q https://github.com/jmbielec/geograpy3.git /tmp/pip-req-build-e2d9uig8\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (3.2.5)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (0.8.9)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (20.7.3)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.7/dist-packages (from geograpy3==1.0.0) (0.2.8)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (0.35.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (4.6.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (6.0.8)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (0.3)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (3.13)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k->geograpy3==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser>=5.2.1->newspaper3k->geograpy3==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==1.0.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==1.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->geograpy3==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->geograpy3==1.0.0) (3.4.0)\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Zxwuu-gyHu"
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29KYdJ0ML0k0"
      },
      "source": [
        "# First lets get a general idea of what our data looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ8YI_sug0f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a54c65d-e337-43cb-cd8d-c0cbadadf1e9"
      },
      "source": [
        "# Count the amount of rows and columns\n",
        "print(\"Shape of train_df:\", train_df.shape)\n",
        "print('\\n\\n')\n",
        "# Counting the amount of missing values\n",
        "print(\"null values:\\n\", train_df.isnull().sum())\n",
        "print('\\n\\n')\n",
        "# Observing the DataFrame's summary\n",
        "train_df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_df: (7613, 5)\n",
            "\n",
            "\n",
            "\n",
            "null values:\n",
            " id             0\n",
            "keyword       61\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IuqsEbkiLrfR",
        "outputId": "35aeaea9-ee6f-4896-f630-5b8b87770deb"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Bii8TY8MydI"
      },
      "source": [
        "\n",
        "*   It looks like we need to fill in some values for keyword and location\n",
        "*   Lets see if we can fill in these values based on what we find in the 'text' values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUa7g1qUFrDh"
      },
      "source": [
        "<h2>Fill in missing values for keyword column </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwP6fnjfPsSp"
      },
      "source": [
        "# create word vector which contains the dissaster keywords\n",
        "dissaster_vector = set(train_df['keyword'].unique());\n",
        "# function which will fill in missing values for keyword column dependent on text column \n",
        "def fillKey(text):\n",
        "  # tokenize the text and store into text_vector\n",
        "  text_vector = set(word_tokenize(text.lower()))\n",
        "  # find the dissaster keywords in text_vector\n",
        "  filler = list(set.intersection(dissaster_vector, text_vector))\n",
        "  # combine the filler array with a delimiter matching that of original format from keyword column\n",
        "  filler = '%20'.join(filler)\n",
        "  return filler"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bNuNtOx51FBP",
        "outputId": "d4de1711-ac14-48b0-da60-e8805e4b1573"
      },
      "source": [
        "# auxilery DataFrame to handle DataFrame.apply()\n",
        "t_df = pd.DataFrame()\n",
        "t_df['keyword'] = train_df['text'].copy()\n",
        "t_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             keyword\n",
              "0  Our Deeds are the Reason of this #earthquake M...\n",
              "1             Forest fire near La Ronge Sask. Canada\n",
              "2  All residents asked to 'shelter in place' are ...\n",
              "3  13,000 people receive #wildfires evacuation or...\n",
              "4  Just got sent this photo from Ruby #Alaska as ..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahwHjNEk-H-v",
        "outputId": "717019b2-0128-4506-aebb-9b803dfce4e2"
      },
      "source": [
        "# fill missing values for keyword column\n",
        "t_df['keyword'] = t_df['keyword'].apply(fillKey)\n",
        "\n",
        "# check if it worked\n",
        "print(t_df.head(), '\\n\\n')\n",
        "print(t_df.isnull().sum())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      keyword\n",
            "0  earthquake\n",
            "1        fire\n",
            "2  evacuation\n",
            "3  evacuation\n",
            "4       smoke \n",
            "\n",
            "\n",
            "keyword    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "lTK3VqmI2PuD",
        "outputId": "b56f415a-fea7-4724-ed07-714f6d000b8d"
      },
      "source": [
        "# before replace missing\n",
        "display(train_df.head())\n",
        "\n",
        "# replacing the missing keyword values\n",
        "train_df['keyword'] = t_df['keyword']\n",
        "\n",
        "# after replace missing\n",
        "display(train_df.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>evacuation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>evacuation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>smoke</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id     keyword  ...                                               text target\n",
              "0   1  earthquake  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4        fire  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5  evacuation  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6  evacuation  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7       smoke  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsH60F0QFgc3"
      },
      "source": [
        "<h2>Now to fill in missing values for locations </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbjVzrx5uCDM"
      },
      "source": [
        "def fillTagLoc(txt):\n",
        "  txt = re.sub(r'[#|@]',r'',txt)\n",
        "  place_entity = locationtagger.find_locations(text = txt)\n",
        "  filler = '%20'.join(set(place_entity.countries + place_entity.regions + place_entity.cities))\n",
        "  return filler"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WQP2TwbJEou"
      },
      "source": [
        "def fillGeoLoc(text_input):\n",
        "  text_input = re.sub(r'[#|@]',r'',text_input)\n",
        "  place_entity = geograpy3.get_place_context(text = text_input)\n",
        "  filler = '%20'.join(set(place_entity.countries + place_entity.regions + place_entity.cities))\n",
        "  return filler"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b0haOQSjoCf",
        "outputId": "eb3e981a-8939-46e7-ddd5-8dc776b57a11"
      },
      "source": [
        "test_str = train_df['text'][5]\n",
        "\n",
        "print(test_str, '\\n\\n')\n",
        "\n",
        "# testing the fillLoc function\n",
        "print('fillTagLoc:\\n',fillTagLoc(test_str), '\\n\\n' )\n",
        "print('fillGeoLoc:\\n',fillGeoLoc(test_str), '\\n\\n' )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires \n",
            "\n",
            "\n",
            "fillTagLoc:\n",
            "  \n",
            "\n",
            "\n",
            "place_entity:  <geograpy3.places.PlaceContext object at 0x7ff39f2a9950>\n",
            "fillGeoLoc:\n",
            " Update%20CAfire%20RockyFire%20Lake County \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6jlQ0cW3GuR"
      },
      "source": [
        "# now that we've gotten keyword column missing values filled in where it could, time to do same for location. \n",
        "# auxilery DataFrame to handle DataFrame.apply()\n",
        "l_df = pd.DataFrame()\n",
        "l_df['location'] = train_df['text'].copy()\n",
        "l_df.head()\n",
        "\n",
        "# fill missing values for keyword column.... ** WARNING !!! this took 17m to execute!\n",
        "l_df['location'] = l_df['location'].apply(fillTagLoc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiVZHFcd2qxl"
      },
      "source": [
        "# check if it worked\n",
        "print(l_df.head(), '\\n\\n')\n",
        "print(l_df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTdgz0J3MAX"
      },
      "source": [
        "# Great! it worked~~~~~~ \n",
        "# before \n",
        "display(train_df.head(10))\n",
        "# now to fill in the missing values \n",
        "train_df['location'].fillna(l_df['location'], inplace=True)\n",
        "# after\n",
        "display(train_df.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fXrrmAO1Pia"
      },
      "source": [
        "# locations using spaCy \n",
        "# using .apply via PandaSeries instead of DataFrame\n",
        "# location_df = train_df[\"text\"].apply(nlp)\n",
        "\n",
        "# print(location_df.ents)\n",
        "# test_df.loc[df['keyword'] == null] = ['ablaze if']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-rq4DSyw1uU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}